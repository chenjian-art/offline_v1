
DATAX_HOME=/opt/module/datax

# å¦‚æœä¼ å…¥æ—¥æœŸåˆ™do_dateç­‰äºä¼ å…¥çš„æ—¥æœŸï¼Œå¦åˆ™ç­‰äºå‰ä¸€å¤©æ—¥æœ
#å¤„ç†ç›®æ ‡è·¯å¾„ï¼Œæ­¤å¤„çš„å¤„ç†é€»è¾‘æ˜¯ï¼Œå¦‚æœç›®æ ‡è·¯å¾„ä¸å­˜åœ¨ï¼Œåˆ™åˆ›å»ºï¼›è‹¥å­˜åœ¨ï¼Œåˆ™æ¸…ç©ºï¼Œç›®çš„æ˜¯ä¿è¯åŒæ­¥ä»»åŠ¡å¯é‡å¤æ‰§è¡Œ
handle_targetdir() {
  hadoop fs -test -e $1
  if [[ $? -eq 1 ]]; then
    echo "è·¯å¾„$1ä¸å­˜åœ¨ï¼Œæ­£åœ¨åˆ›å»º......"
    hadoop fs -mkdir -p $1
  else
    echo "è·¯å¾„$1å·²ç»å­˜åœ¨"
    fs_count=$(hadoop fs -count $1)
    content_size=$(echo $fs_count | awk '{print $3}')
    if [[ $content_size -eq 0 ]]; then
      echo "è·¯å¾„$1ä¸ºç©º"
    else
      echo "è·¯å¾„$1ä¸ä¸ºç©ºï¼Œæ­£åœ¨æ¸…ç©º......"
      hadoop fs -rm -r -f $1/*
    fi
  fi
}
#æ•°æ®åŒæ­¥
import_data() {
  datax_config=$1
  target_dir=$2

  handle_targetdir $target_dir
  python $DATAX_HOME/bin/datax.py -p"-Dtargetdir=$target_dir" $datax_config

}
import_data /opt/module/datax/job/gift/Broadcast.ods_anchor_info.json /data/gift/ods_anchor_info
import_data /opt/module/datax/job/gift/Broadcast.ods_Acknowledge.json /data/gift/ods_Acknowledge
import_data /opt/module/datax/job/gift/Broadcast.ods_common.json /data/gift/ods_common
import_data /opt/module/datax/job/gift/Broadcast.ods_lucky.json /data/gift/ods_lucky
import_data /opt/module/datax/job/gift/Broadcast.ods_prop.json /data/gift/ods_prop

